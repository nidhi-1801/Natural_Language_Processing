{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeLWzQK5geJXHAfbpUr+su",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nidhi-1801/Natural_Language_Processing/blob/main/Bag_of_Words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "dp_1YTzzqHeS",
        "outputId": "6b0f1f64-759c-4339-86a4-edf4599fcb71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"When text is stored in a file, it’s saved as bytes (numbers) — not characters directly.\\nAn encoding tells Python how to interpret those bytes as readable text (like letters, symbols, emojis, etc.).\\n\\nCommon encodings include:\\n\\n'utf-8' — the most widely used and standard format\\n\\n'latin-1' — also called ISO-8859-1, supports many European characters\\n\\n'ascii' — only supports basic English letters and symbols\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#import libraries and load dataset\n",
        "import pandas as pd\n",
        "df = pd.read_csv('spam.csv',encoding='latin-1')\n",
        "\n",
        "'''When text is stored in a file, it’s saved as bytes (numbers) — not characters directly.\n",
        "An encoding tells Python how to interpret those bytes as readable text (like letters, symbols, emojis, etc.).\n",
        "\n",
        "Common encodings include:\n",
        "\n",
        "'utf-8' — the most widely used and standard format\n",
        "\n",
        "'latin-1' — also called ISO-8859-1, supports many European characters\n",
        "\n",
        "'ascii' — only supports basic English letters and symbols'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2️⃣ — Keep only necessary columns\n",
        "df = df[['v1', 'v2']]\n",
        "#renaming column names\n",
        "df.columns = [\"label\",\"message\"]"
      ],
      "metadata": {
        "id": "rVWeKuWAs65a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3\n",
        "'''Removing stopwords\n",
        "Stemming\n",
        "Lowercase'''\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32zBePKpuM5o",
        "outputId": "0325c056-2d0f-4b1a-8862-9bea79887d68"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=[]\n",
        "for i in range(0,len(df)):\n",
        "  review = re.sub('[^a-zA-Z]',' ',df['message'][i])   # Substituing all special characters with blank space (i.e excep a-z, A-Z)\n",
        "  review = review.lower() #converting all text into lower\n",
        "  review = review.split() # to get list of words\n",
        "  # remove stopwords and apply stemming\n",
        "  review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "  # join cleaned words back into one string\n",
        "  review = ' '.join(review)\n",
        "  corpus.append(review)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PIvl85GSuM3N"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Applying Bag of Words\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=2500)# Extract the top 2500 most frequent words (features) from the text corpus"
      ],
      "metadata": {
        "id": "XTipFuOruMy2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=cv.fit_transform(corpus).toarray()\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsefcInNykhA",
        "outputId": "f5e4686f-c4b7-41cc-938e-a6ca3c99f25f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}